{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOlo4Ctmtm4p"
   },
   "source": [
    "# Transfer Learning Assignment\n",
    "반갑습니다 여러분. 과제를 맡은 김준호입니다. TL 세션에서 다룬 Fine-tuning과 Domain Adaptation을 직접 구현해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWlAlAeRtm4s"
   },
   "source": [
    "Office-31은 여러 실습에서 자주 등장하는 이미지 데이터셋입니다. Amazon, Webcam, DSLR 세 개의 도메인으로 구성되어 있는데요. \n",
    "\n",
    "총 31개 클래스 (키보드, 마우스, 모니터 등)의 사무용품 이미지가 있고,각 도메인마다 같은 클래스가 포함되어 있지만 도메인마다 이미지 특성은 다릅니다. \n",
    "\n",
    "그래서 이런 transfer learning 실습에 적합하다고 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6R098oQTS_TC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torchvision import models\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9Ut17hwUDq-"
   },
   "source": [
    "amazon을 source로, webcam을 target data로 이용해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j4e--IIRU68M"
   },
   "outputs": [],
   "source": [
    "data_folder = 'office31/OFFICE31'\n",
    "batch_size = 32\n",
    "n_class = 31\n",
    "domain_src, domain_tar = 'amazon', 'webcam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XA6e2YaPtm4u"
   },
   "source": [
    "source와 target domain에 대한 DataLoader를 생성하고 load해 줍시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6JtN_bK9VFcM"
   },
   "outputs": [],
   "source": [
    "def load_data(root_path, domain, batch_size, phase):\n",
    "    transform_dict = {\n",
    "        'src': transforms.Compose(\n",
    "        [transforms.RandomResizedCrop(224),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "         ]),\n",
    "        'tar': transforms.Compose(\n",
    "        [transforms.Resize(224),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "         ])}\n",
    "    data = datasets.ImageFolder(root=os.path.join(root_path, domain), transform=transform_dict[phase])\n",
    "    data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=phase=='src', drop_last=phase=='tar', num_workers=4)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Jf_Gw2HRVJM_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source data number: 2817\n",
      "Target data number: 795\n"
     ]
    }
   ],
   "source": [
    "src_loader = load_data(data_folder, domain_src, batch_size, phase='src')\n",
    "tar_loader = load_data(data_folder, domain_tar, batch_size, phase='tar')\n",
    "print(f'Source data number: {len(src_loader.dataset)}')\n",
    "print(f'Target data number: {len(tar_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caKMn438tm4v"
   },
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-trained ResNet50을 기반으로 한 간단한 TransferModel을 정의합니다. 여기서 모델 구조는 유지하되 마지막 fc layer만 새롭게 학습되도록 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OXAjmY7pVK8t"
   },
   "outputs": [],
   "source": [
    "class TransferModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                base_model : str = 'resnet50',\n",
    "                pretrain : bool = True,\n",
    "                n_class : int = 31):\n",
    "        super(TransferModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.pretrain = pretrain\n",
    "        self.n_class = n_class\n",
    "        if self.base_model == 'resnet50':\n",
    "            self.model = models.resnet50(pretrained=self.pretrain) # TODO: pre-trained model 불러오기\n",
    "            n_features = self.model.fc.in_features\n",
    "            fc = nn.Linear(n_features, self.n_class) # TODO: 새로운 fc layer를 정의\n",
    "            self.model.fc = fc # TODO: 모델의 fc layer를 새로운 fc로 교체\n",
    "\n",
    "        else:\n",
    "            # Use other models you like, such as vgg or alexnet\n",
    "            pass\n",
    "        self.model.fc.weight.data.normal_(0, 0.005)\n",
    "        self.model.fc.bias.data.fill_(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAqT-0jRtm4w"
   },
   "source": [
    "모델이 정상적으로 작동하는지 random tensor로 테스트해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LewRmYIvXEIo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0294,  0.2437,  0.1822,  0.1386,  0.0959,  0.1343, -0.0929,  0.2820,\n",
      "          0.0088,  0.0342, -0.1268, -0.1844, -0.0713,  0.2256,  0.1873,  0.1967,\n",
      "          0.0806,  0.0243,  0.1150,  0.1818,  0.1234,  0.0433,  0.2735,  0.0942,\n",
      "          0.0682,  0.1362,  0.2368,  0.0429,  0.0806, -0.0511,  0.1191]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 31])\n"
     ]
    }
   ],
   "source": [
    "model = TransferModel().cuda()\n",
    "RAND_TENSOR = torch.randn(1, 3, 224, 224).cuda()\n",
    "output = model(RAND_TENSOR)\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpX-fuiXtm4w"
   },
   "source": [
    "## Finetune ResNet-50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uNeAiPatm4w"
   },
   "source": [
    "Office-31 dataset은 validation set이 따로 없으므로, validation set으로 target domain을 이용해 줍시다.\n",
    "\n",
    "fine-tuning을 위한 학습 및 평가 함수를 정의합니다.\n",
    "학습은 source domain에서 수행하고 target domain에서 검증합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "h74gKIVqtm4w"
   },
   "outputs": [],
   "source": [
    "dataloaders = {'src': src_loader,\n",
    "               'val': tar_loader,\n",
    "               'tar': tar_loader}\n",
    "n_epoch = 100\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "early_stop = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-fz_FlAIXsTF"
   },
   "outputs": [],
   "source": [
    "def finetune(model, dataloaders, optimizer):\n",
    "    since = time.time()\n",
    "    best_acc = 0\n",
    "    stop = 0\n",
    "    for epoch in range(0, n_epoch):\n",
    "        stop += 1\n",
    "        # You can uncomment this line for scheduling learning rate\n",
    "        # lr_schedule(optimizer, epoch)\n",
    "        for phase in ['src', 'val', 'tar']:\n",
    "            if phase == 'src':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            total_loss, correct = 0, 0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'src'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                preds = torch.max(outputs, 1)[1]\n",
    "                if phase == 'src':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "                correct += torch.sum(preds == labels.data)\n",
    "            epoch_loss = total_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = correct.double() / len(dataloaders[phase].dataset)\n",
    "            print(f'Epoch: [{epoch:02d}/{n_epoch:02d}]---{phase}, loss: {epoch_loss:.6f}, acc: {epoch_acc:.4f}')\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                stop = 0\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), 'model.pkl')\n",
    "        if stop >= early_stop:\n",
    "            break\n",
    "        print()\n",
    "   \n",
    "    time_pass = time.time() - since\n",
    "    print(f'Training complete in {time_pass // 60:.0f}m {time_pass % 60:.0f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGUZGrm7tm4x"
   },
   "source": [
    "이제 학습 파라미터들과 optimizer를 정의합니다.\n",
    "간단하게 SGD optimizer를 사용하고 fc layer의 학습률을 다른 layer보다 10배 크게 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HGVIu0JXZaGT"
   },
   "outputs": [],
   "source": [
    "param_group = []\n",
    "learning_rate = 0.0001\n",
    "momentum = 5e-4\n",
    "for k, v in model.named_parameters():\n",
    "    if not k.__contains__('fc'):\n",
    "        param_group += [{'params': v, 'lr': learning_rate}]\n",
    "    else:\n",
    "        param_group += [{'params': v, 'lr': learning_rate * 10}]\n",
    "optimizer = torch.optim.SGD(param_group, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7zGR_PFtm4y"
   },
   "source": [
    "## Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uKKrah-AZsHt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [00/100]---src, loss: 3.377823, acc: 0.1186\n",
      "Epoch: [00/100]---val, loss: 3.198652, acc: 0.1497\n",
      "Epoch: [00/100]---tar, loss: 3.198652, acc: 0.1497\n",
      "\n",
      "Epoch: [01/100]---src, loss: 3.244426, acc: 0.3397\n",
      "Epoch: [01/100]---val, loss: 3.078928, acc: 0.1522\n",
      "Epoch: [01/100]---tar, loss: 3.078928, acc: 0.1522\n",
      "\n",
      "Epoch: [02/100]---src, loss: 3.122124, acc: 0.4121\n",
      "Epoch: [02/100]---val, loss: 2.957325, acc: 0.4239\n",
      "Epoch: [02/100]---tar, loss: 2.957325, acc: 0.4239\n",
      "\n",
      "Epoch: [03/100]---src, loss: 2.996710, acc: 0.5335\n",
      "Epoch: [03/100]---val, loss: 2.852715, acc: 0.2528\n",
      "Epoch: [03/100]---tar, loss: 2.852715, acc: 0.2528\n",
      "\n",
      "Epoch: [04/100]---src, loss: 2.873716, acc: 0.5556\n",
      "Epoch: [04/100]---val, loss: 2.751970, acc: 0.4755\n",
      "Epoch: [04/100]---tar, loss: 2.751970, acc: 0.4755\n",
      "\n",
      "Epoch: [05/100]---src, loss: 2.754337, acc: 0.5925\n",
      "Epoch: [05/100]---val, loss: 2.623909, acc: 0.5484\n",
      "Epoch: [05/100]---tar, loss: 2.623909, acc: 0.5484\n",
      "\n",
      "Epoch: [06/100]---src, loss: 2.630971, acc: 0.6258\n",
      "Epoch: [06/100]---val, loss: 2.506690, acc: 0.5950\n",
      "Epoch: [06/100]---tar, loss: 2.506690, acc: 0.5950\n",
      "\n",
      "Epoch: [07/100]---src, loss: 2.524108, acc: 0.6386\n",
      "Epoch: [07/100]---val, loss: 2.389399, acc: 0.6151\n",
      "Epoch: [07/100]---tar, loss: 2.389399, acc: 0.6151\n",
      "\n",
      "Epoch: [08/100]---src, loss: 2.412304, acc: 0.6429\n",
      "Epoch: [08/100]---val, loss: 2.295898, acc: 0.6314\n",
      "Epoch: [08/100]---tar, loss: 2.295898, acc: 0.6314\n",
      "\n",
      "Epoch: [09/100]---src, loss: 2.308775, acc: 0.6553\n",
      "Epoch: [09/100]---val, loss: 2.208792, acc: 0.6289\n",
      "Epoch: [09/100]---tar, loss: 2.208792, acc: 0.6289\n",
      "\n",
      "Epoch: [10/100]---src, loss: 2.214598, acc: 0.6663\n",
      "Epoch: [10/100]---val, loss: 2.099608, acc: 0.6440\n",
      "Epoch: [10/100]---tar, loss: 2.099608, acc: 0.6440\n",
      "\n",
      "Epoch: [11/100]---src, loss: 2.115910, acc: 0.6723\n",
      "Epoch: [11/100]---val, loss: 2.014295, acc: 0.6579\n",
      "Epoch: [11/100]---tar, loss: 2.014295, acc: 0.6579\n",
      "\n",
      "Epoch: [12/100]---src, loss: 2.027439, acc: 0.6798\n",
      "Epoch: [12/100]---val, loss: 1.966433, acc: 0.6717\n",
      "Epoch: [12/100]---tar, loss: 1.966433, acc: 0.6717\n",
      "\n",
      "Epoch: [13/100]---src, loss: 1.954171, acc: 0.6961\n",
      "Epoch: [13/100]---val, loss: 1.878384, acc: 0.6654\n",
      "Epoch: [13/100]---tar, loss: 1.878384, acc: 0.6654\n",
      "\n",
      "Epoch: [14/100]---src, loss: 1.875096, acc: 0.7007\n",
      "Epoch: [14/100]---val, loss: 1.809528, acc: 0.6881\n",
      "Epoch: [14/100]---tar, loss: 1.809528, acc: 0.6881\n",
      "\n",
      "Epoch: [15/100]---src, loss: 1.800526, acc: 0.6972\n",
      "Epoch: [15/100]---val, loss: 1.763401, acc: 0.6616\n",
      "Epoch: [15/100]---tar, loss: 1.763401, acc: 0.6616\n",
      "\n",
      "Epoch: [16/100]---src, loss: 1.747418, acc: 0.7000\n",
      "Epoch: [16/100]---val, loss: 1.701725, acc: 0.6868\n",
      "Epoch: [16/100]---tar, loss: 1.701725, acc: 0.6868\n",
      "\n",
      "Epoch: [17/100]---src, loss: 1.680187, acc: 0.7107\n",
      "Epoch: [17/100]---val, loss: 1.630425, acc: 0.6994\n",
      "Epoch: [17/100]---tar, loss: 1.630425, acc: 0.6994\n",
      "\n",
      "Epoch: [18/100]---src, loss: 1.632043, acc: 0.7114\n",
      "Epoch: [18/100]---val, loss: 1.551986, acc: 0.7119\n",
      "Epoch: [18/100]---tar, loss: 1.551986, acc: 0.7119\n",
      "\n",
      "Epoch: [19/100]---src, loss: 1.576737, acc: 0.7174\n",
      "Epoch: [19/100]---val, loss: 1.565958, acc: 0.6855\n",
      "Epoch: [19/100]---tar, loss: 1.565958, acc: 0.6855\n",
      "\n",
      "Epoch: [20/100]---src, loss: 1.518818, acc: 0.7242\n",
      "Epoch: [20/100]---val, loss: 1.509720, acc: 0.7057\n",
      "Epoch: [20/100]---tar, loss: 1.509720, acc: 0.7057\n",
      "\n",
      "Epoch: [21/100]---src, loss: 1.493483, acc: 0.7210\n",
      "Epoch: [21/100]---val, loss: 1.482034, acc: 0.6969\n",
      "Epoch: [21/100]---tar, loss: 1.482034, acc: 0.6969\n",
      "\n",
      "Epoch: [22/100]---src, loss: 1.454846, acc: 0.7224\n",
      "Epoch: [22/100]---val, loss: 1.450947, acc: 0.7044\n",
      "Epoch: [22/100]---tar, loss: 1.450947, acc: 0.7044\n",
      "\n",
      "Epoch: [23/100]---src, loss: 1.399385, acc: 0.7423\n",
      "Epoch: [23/100]---val, loss: 1.376124, acc: 0.7182\n",
      "Epoch: [23/100]---tar, loss: 1.376124, acc: 0.7182\n",
      "\n",
      "Epoch: [24/100]---src, loss: 1.373391, acc: 0.7441\n",
      "Epoch: [24/100]---val, loss: 1.316170, acc: 0.7308\n",
      "Epoch: [24/100]---tar, loss: 1.316170, acc: 0.7308\n",
      "\n",
      "Epoch: [25/100]---src, loss: 1.353519, acc: 0.7373\n",
      "Epoch: [25/100]---val, loss: 1.343842, acc: 0.7296\n",
      "Epoch: [25/100]---tar, loss: 1.343842, acc: 0.7296\n",
      "\n",
      "Epoch: [26/100]---src, loss: 1.313922, acc: 0.7437\n",
      "Epoch: [26/100]---val, loss: 1.319156, acc: 0.7069\n",
      "Epoch: [26/100]---tar, loss: 1.319156, acc: 0.7069\n",
      "\n",
      "Epoch: [27/100]---src, loss: 1.269361, acc: 0.7401\n",
      "Epoch: [27/100]---val, loss: 1.275494, acc: 0.7019\n",
      "Epoch: [27/100]---tar, loss: 1.275494, acc: 0.7019\n",
      "\n",
      "Epoch: [28/100]---src, loss: 1.251464, acc: 0.7458\n",
      "Epoch: [28/100]---val, loss: 1.237760, acc: 0.7195\n",
      "Epoch: [28/100]---tar, loss: 1.237760, acc: 0.7195\n",
      "\n",
      "Epoch: [29/100]---src, loss: 1.253917, acc: 0.7348\n",
      "Epoch: [29/100]---val, loss: 1.226815, acc: 0.7094\n",
      "Epoch: [29/100]---tar, loss: 1.226815, acc: 0.7094\n",
      "\n",
      "Epoch: [30/100]---src, loss: 1.198215, acc: 0.7508\n",
      "Epoch: [30/100]---val, loss: 1.217695, acc: 0.7006\n",
      "Epoch: [30/100]---tar, loss: 1.217695, acc: 0.7006\n",
      "\n",
      "Epoch: [31/100]---src, loss: 1.176691, acc: 0.7501\n",
      "Epoch: [31/100]---val, loss: 1.204834, acc: 0.7145\n",
      "Epoch: [31/100]---tar, loss: 1.204834, acc: 0.7145\n",
      "\n",
      "Epoch: [32/100]---src, loss: 1.163758, acc: 0.7618\n",
      "Epoch: [32/100]---val, loss: 1.194406, acc: 0.7019\n",
      "Epoch: [32/100]---tar, loss: 1.194406, acc: 0.7019\n",
      "\n",
      "Epoch: [33/100]---src, loss: 1.142721, acc: 0.7579\n",
      "Epoch: [33/100]---val, loss: 1.163663, acc: 0.7270\n",
      "Epoch: [33/100]---tar, loss: 1.163663, acc: 0.7270\n",
      "\n",
      "Epoch: [34/100]---src, loss: 1.112967, acc: 0.7639\n",
      "Epoch: [34/100]---val, loss: 1.162203, acc: 0.7208\n",
      "Epoch: [34/100]---tar, loss: 1.162203, acc: 0.7208\n",
      "\n",
      "Epoch: [35/100]---src, loss: 1.099951, acc: 0.7717\n",
      "Epoch: [35/100]---val, loss: 1.141423, acc: 0.7069\n",
      "Epoch: [35/100]---tar, loss: 1.141423, acc: 0.7069\n",
      "\n",
      "Epoch: [36/100]---src, loss: 1.099917, acc: 0.7618\n",
      "Epoch: [36/100]---val, loss: 1.154968, acc: 0.7094\n",
      "Epoch: [36/100]---tar, loss: 1.154968, acc: 0.7094\n",
      "\n",
      "Epoch: [37/100]---src, loss: 1.063322, acc: 0.7689\n",
      "Epoch: [37/100]---val, loss: 1.100925, acc: 0.7296\n",
      "Epoch: [37/100]---tar, loss: 1.100925, acc: 0.7296\n",
      "\n",
      "Epoch: [38/100]---src, loss: 1.082890, acc: 0.7579\n",
      "Epoch: [38/100]---val, loss: 1.099303, acc: 0.7157\n",
      "Epoch: [38/100]---tar, loss: 1.099303, acc: 0.7157\n",
      "\n",
      "Epoch: [39/100]---src, loss: 1.050690, acc: 0.7643\n",
      "Epoch: [39/100]---val, loss: 1.115349, acc: 0.7145\n",
      "Epoch: [39/100]---tar, loss: 1.115349, acc: 0.7145\n",
      "\n",
      "Epoch: [40/100]---src, loss: 1.037751, acc: 0.7707\n",
      "Epoch: [40/100]---val, loss: 1.051328, acc: 0.7258\n",
      "Epoch: [40/100]---tar, loss: 1.051328, acc: 0.7258\n",
      "\n",
      "Epoch: [41/100]---src, loss: 1.023106, acc: 0.7661\n",
      "Epoch: [41/100]---val, loss: 1.099016, acc: 0.7057\n",
      "Epoch: [41/100]---tar, loss: 1.099016, acc: 0.7057\n",
      "\n",
      "Epoch: [42/100]---src, loss: 1.007907, acc: 0.7767\n",
      "Epoch: [42/100]---val, loss: 1.028986, acc: 0.7434\n",
      "Epoch: [42/100]---tar, loss: 1.028986, acc: 0.7434\n",
      "\n",
      "Epoch: [43/100]---src, loss: 1.004355, acc: 0.7788\n",
      "Epoch: [43/100]---val, loss: 1.046140, acc: 0.7208\n",
      "Epoch: [43/100]---tar, loss: 1.046140, acc: 0.7208\n",
      "\n",
      "Epoch: [44/100]---src, loss: 0.956270, acc: 0.7941\n",
      "Epoch: [44/100]---val, loss: 1.054770, acc: 0.7245\n",
      "Epoch: [44/100]---tar, loss: 1.054770, acc: 0.7245\n",
      "\n",
      "Epoch: [45/100]---src, loss: 0.995446, acc: 0.7767\n",
      "Epoch: [45/100]---val, loss: 1.025985, acc: 0.7157\n",
      "Epoch: [45/100]---tar, loss: 1.025985, acc: 0.7157\n",
      "\n",
      "Epoch: [46/100]---src, loss: 0.956415, acc: 0.7831\n",
      "Epoch: [46/100]---val, loss: 1.007940, acc: 0.7283\n",
      "Epoch: [46/100]---tar, loss: 1.007940, acc: 0.7283\n",
      "\n",
      "Epoch: [47/100]---src, loss: 0.931895, acc: 0.7820\n",
      "Epoch: [47/100]---val, loss: 1.050894, acc: 0.7132\n",
      "Epoch: [47/100]---tar, loss: 1.050894, acc: 0.7132\n",
      "\n",
      "Epoch: [48/100]---src, loss: 0.952978, acc: 0.7678\n",
      "Epoch: [48/100]---val, loss: 1.005865, acc: 0.7296\n",
      "Epoch: [48/100]---tar, loss: 1.005865, acc: 0.7296\n",
      "\n",
      "Epoch: [49/100]---src, loss: 0.949619, acc: 0.7799\n",
      "Epoch: [49/100]---val, loss: 0.995400, acc: 0.7208\n",
      "Epoch: [49/100]---tar, loss: 0.995400, acc: 0.7208\n",
      "\n",
      "Epoch: [50/100]---src, loss: 0.930523, acc: 0.7874\n",
      "Epoch: [50/100]---val, loss: 0.955426, acc: 0.7421\n",
      "Epoch: [50/100]---tar, loss: 0.955426, acc: 0.7421\n",
      "\n",
      "Epoch: [51/100]---src, loss: 0.921021, acc: 0.7884\n",
      "Epoch: [51/100]---val, loss: 1.024504, acc: 0.7044\n",
      "Epoch: [51/100]---tar, loss: 1.024504, acc: 0.7044\n",
      "\n",
      "Epoch: [52/100]---src, loss: 0.893778, acc: 0.7927\n",
      "Epoch: [52/100]---val, loss: 0.984564, acc: 0.7333\n",
      "Epoch: [52/100]---tar, loss: 0.984564, acc: 0.7333\n",
      "\n",
      "Epoch: [53/100]---src, loss: 0.893356, acc: 0.7870\n",
      "Epoch: [53/100]---val, loss: 0.926185, acc: 0.7535\n",
      "Epoch: [53/100]---tar, loss: 0.926185, acc: 0.7535\n",
      "\n",
      "Epoch: [54/100]---src, loss: 0.889521, acc: 0.7813\n",
      "Epoch: [54/100]---val, loss: 0.924324, acc: 0.7308\n",
      "Epoch: [54/100]---tar, loss: 0.924324, acc: 0.7308\n",
      "\n",
      "Epoch: [55/100]---src, loss: 0.900799, acc: 0.7831\n",
      "Epoch: [55/100]---val, loss: 0.940592, acc: 0.7333\n",
      "Epoch: [55/100]---tar, loss: 0.940592, acc: 0.7333\n",
      "\n",
      "Epoch: [56/100]---src, loss: 0.875951, acc: 0.7987\n",
      "Epoch: [56/100]---val, loss: 0.929445, acc: 0.7421\n",
      "Epoch: [56/100]---tar, loss: 0.929445, acc: 0.7421\n",
      "\n",
      "Epoch: [57/100]---src, loss: 0.859725, acc: 0.7902\n",
      "Epoch: [57/100]---val, loss: 0.933889, acc: 0.7258\n",
      "Epoch: [57/100]---tar, loss: 0.933889, acc: 0.7258\n",
      "\n",
      "Epoch: [58/100]---src, loss: 0.857686, acc: 0.7916\n",
      "Epoch: [58/100]---val, loss: 0.925354, acc: 0.7434\n",
      "Epoch: [58/100]---tar, loss: 0.925354, acc: 0.7434\n",
      "\n",
      "Epoch: [59/100]---src, loss: 0.849049, acc: 0.8019\n",
      "Epoch: [59/100]---val, loss: 0.950759, acc: 0.7220\n",
      "Epoch: [59/100]---tar, loss: 0.950759, acc: 0.7220\n",
      "\n",
      "Epoch: [60/100]---src, loss: 0.865585, acc: 0.7884\n",
      "Epoch: [60/100]---val, loss: 0.894879, acc: 0.7421\n",
      "Epoch: [60/100]---tar, loss: 0.894879, acc: 0.7421\n",
      "\n",
      "Epoch: [61/100]---src, loss: 0.854306, acc: 0.7916\n",
      "Epoch: [61/100]---val, loss: 0.900948, acc: 0.7358\n",
      "Epoch: [61/100]---tar, loss: 0.900948, acc: 0.7358\n",
      "\n",
      "Epoch: [62/100]---src, loss: 0.848011, acc: 0.8001\n",
      "Epoch: [62/100]---val, loss: 0.921038, acc: 0.7233\n",
      "Epoch: [62/100]---tar, loss: 0.921038, acc: 0.7233\n",
      "\n",
      "Epoch: [63/100]---src, loss: 0.839157, acc: 0.7863\n",
      "Epoch: [63/100]---val, loss: 0.882935, acc: 0.7384\n",
      "Epoch: [63/100]---tar, loss: 0.882935, acc: 0.7384\n",
      "\n",
      "Epoch: [64/100]---src, loss: 0.831359, acc: 0.7906\n",
      "Epoch: [64/100]---val, loss: 0.884231, acc: 0.7384\n",
      "Epoch: [64/100]---tar, loss: 0.884231, acc: 0.7384\n",
      "\n",
      "Epoch: [65/100]---src, loss: 0.821505, acc: 0.7966\n",
      "Epoch: [65/100]---val, loss: 0.877311, acc: 0.7346\n",
      "Epoch: [65/100]---tar, loss: 0.877311, acc: 0.7346\n",
      "\n",
      "Epoch: [66/100]---src, loss: 0.827868, acc: 0.7895\n",
      "Epoch: [66/100]---val, loss: 0.875817, acc: 0.7308\n",
      "Epoch: [66/100]---tar, loss: 0.875817, acc: 0.7308\n",
      "\n",
      "Epoch: [67/100]---src, loss: 0.802311, acc: 0.8055\n",
      "Epoch: [67/100]---val, loss: 0.875844, acc: 0.7333\n",
      "Epoch: [67/100]---tar, loss: 0.875844, acc: 0.7333\n",
      "\n",
      "Epoch: [68/100]---src, loss: 0.799959, acc: 0.8023\n",
      "Epoch: [68/100]---val, loss: 0.870676, acc: 0.7409\n",
      "Epoch: [68/100]---tar, loss: 0.870676, acc: 0.7409\n",
      "\n",
      "Epoch: [69/100]---src, loss: 0.819456, acc: 0.8009\n",
      "Epoch: [69/100]---val, loss: 0.849705, acc: 0.7560\n",
      "Epoch: [69/100]---tar, loss: 0.849705, acc: 0.7560\n",
      "\n",
      "Epoch: [70/100]---src, loss: 0.806549, acc: 0.7941\n",
      "Epoch: [70/100]---val, loss: 0.864998, acc: 0.7484\n",
      "Epoch: [70/100]---tar, loss: 0.864998, acc: 0.7484\n",
      "\n",
      "Epoch: [71/100]---src, loss: 0.789585, acc: 0.8023\n",
      "Epoch: [71/100]---val, loss: 0.891566, acc: 0.7270\n",
      "Epoch: [71/100]---tar, loss: 0.891566, acc: 0.7270\n",
      "\n",
      "Epoch: [72/100]---src, loss: 0.787522, acc: 0.8076\n",
      "Epoch: [72/100]---val, loss: 0.874168, acc: 0.7358\n",
      "Epoch: [72/100]---tar, loss: 0.874168, acc: 0.7358\n",
      "\n",
      "Epoch: [73/100]---src, loss: 0.789678, acc: 0.8023\n",
      "Epoch: [73/100]---val, loss: 0.838702, acc: 0.7610\n",
      "Epoch: [73/100]---tar, loss: 0.838702, acc: 0.7610\n",
      "\n",
      "Epoch: [74/100]---src, loss: 0.770698, acc: 0.8090\n",
      "Epoch: [74/100]---val, loss: 0.834593, acc: 0.7497\n",
      "Epoch: [74/100]---tar, loss: 0.834593, acc: 0.7497\n",
      "\n",
      "Epoch: [75/100]---src, loss: 0.769124, acc: 0.8037\n",
      "Epoch: [75/100]---val, loss: 0.864959, acc: 0.7371\n",
      "Epoch: [75/100]---tar, loss: 0.864959, acc: 0.7371\n",
      "\n",
      "Epoch: [76/100]---src, loss: 0.755336, acc: 0.8108\n",
      "Epoch: [76/100]---val, loss: 0.858666, acc: 0.7346\n",
      "Epoch: [76/100]---tar, loss: 0.858666, acc: 0.7346\n",
      "\n",
      "Epoch: [77/100]---src, loss: 0.755606, acc: 0.8101\n",
      "Epoch: [77/100]---val, loss: 0.852467, acc: 0.7308\n",
      "Epoch: [77/100]---tar, loss: 0.852467, acc: 0.7308\n",
      "\n",
      "Epoch: [78/100]---src, loss: 0.774311, acc: 0.8069\n",
      "Epoch: [78/100]---val, loss: 0.850563, acc: 0.7396\n",
      "Epoch: [78/100]---tar, loss: 0.850563, acc: 0.7396\n",
      "\n",
      "Epoch: [79/100]---src, loss: 0.747362, acc: 0.8062\n",
      "Epoch: [79/100]---val, loss: 0.845439, acc: 0.7270\n",
      "Epoch: [79/100]---tar, loss: 0.845439, acc: 0.7270\n",
      "\n",
      "Epoch: [80/100]---src, loss: 0.743804, acc: 0.8140\n",
      "Epoch: [80/100]---val, loss: 0.821707, acc: 0.7434\n",
      "Epoch: [80/100]---tar, loss: 0.821707, acc: 0.7434\n",
      "\n",
      "Epoch: [81/100]---src, loss: 0.734870, acc: 0.8136\n",
      "Epoch: [81/100]---val, loss: 0.819881, acc: 0.7535\n",
      "Epoch: [81/100]---tar, loss: 0.819881, acc: 0.7535\n",
      "\n",
      "Epoch: [82/100]---src, loss: 0.739761, acc: 0.8111\n",
      "Epoch: [82/100]---val, loss: 0.894436, acc: 0.7258\n",
      "Epoch: [82/100]---tar, loss: 0.894436, acc: 0.7258\n",
      "\n",
      "Epoch: [83/100]---src, loss: 0.744208, acc: 0.8115\n",
      "Epoch: [83/100]---val, loss: 0.806334, acc: 0.7459\n",
      "Epoch: [83/100]---tar, loss: 0.806334, acc: 0.7459\n",
      "\n",
      "Epoch: [84/100]---src, loss: 0.733203, acc: 0.8122\n",
      "Epoch: [84/100]---val, loss: 0.818505, acc: 0.7308\n",
      "Epoch: [84/100]---tar, loss: 0.818505, acc: 0.7308\n",
      "\n",
      "Epoch: [85/100]---src, loss: 0.722019, acc: 0.8197\n",
      "Epoch: [85/100]---val, loss: 0.855868, acc: 0.7308\n",
      "Epoch: [85/100]---tar, loss: 0.855868, acc: 0.7308\n",
      "\n",
      "Epoch: [86/100]---src, loss: 0.724442, acc: 0.8101\n",
      "Epoch: [86/100]---val, loss: 0.823106, acc: 0.7409\n",
      "Epoch: [86/100]---tar, loss: 0.823106, acc: 0.7409\n",
      "\n",
      "Epoch: [87/100]---src, loss: 0.724393, acc: 0.8076\n",
      "Epoch: [87/100]---val, loss: 0.799629, acc: 0.7434\n",
      "Epoch: [87/100]---tar, loss: 0.799629, acc: 0.7434\n",
      "\n",
      "Epoch: [88/100]---src, loss: 0.723588, acc: 0.8083\n",
      "Epoch: [88/100]---val, loss: 0.815148, acc: 0.7358\n",
      "Epoch: [88/100]---tar, loss: 0.815148, acc: 0.7358\n",
      "\n",
      "Epoch: [89/100]---src, loss: 0.715424, acc: 0.8151\n",
      "Epoch: [89/100]---val, loss: 0.830976, acc: 0.7434\n",
      "Epoch: [89/100]---tar, loss: 0.830976, acc: 0.7434\n",
      "\n",
      "Epoch: [90/100]---src, loss: 0.716931, acc: 0.8108\n",
      "Epoch: [90/100]---val, loss: 0.847306, acc: 0.7333\n",
      "Epoch: [90/100]---tar, loss: 0.847306, acc: 0.7333\n",
      "\n",
      "Epoch: [91/100]---src, loss: 0.700671, acc: 0.8246\n",
      "Epoch: [91/100]---val, loss: 0.828253, acc: 0.7245\n",
      "Epoch: [91/100]---tar, loss: 0.828253, acc: 0.7245\n",
      "\n",
      "Epoch: [92/100]---src, loss: 0.710631, acc: 0.8225\n",
      "Epoch: [92/100]---val, loss: 0.799860, acc: 0.7509\n",
      "Epoch: [92/100]---tar, loss: 0.799860, acc: 0.7509\n",
      "\n",
      "Epoch: [93/100]---src, loss: 0.713639, acc: 0.8186\n",
      "Epoch: [93/100]---val, loss: 0.847299, acc: 0.7308\n",
      "Epoch: [93/100]---tar, loss: 0.847299, acc: 0.7308\n",
      "Training complete in 14m 34s\n"
     ]
    }
   ],
   "source": [
    "# TODO: fine-tuning function 호출하여 학습 진행\n",
    "finetune(model, dataloaders, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GR5Y1x4btm4y"
   },
   "outputs": [],
   "source": [
    "def test(model, target_test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    len_target_dataset = len(target_test_loader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for data, target in target_test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            s_output = model.predict(data)\n",
    "            pred = torch.max(s_output, 1)[1]\n",
    "            correct += torch.sum(pred == target)\n",
    "    acc = correct.double() / len(target_test_loader.dataset)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1O2CBxmxtm4y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.761006289308176\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pkl'))\n",
    "acc_test = test(model, dataloaders['tar'])\n",
    "print(f'Test accuracy: {acc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7Iuk_Mitm4z"
   },
   "source": [
    "여기까지가 fine-tuning 파트입니다. 실제 학습에서는 learning rate decay 같은 기법도 사용하지만, 이 과제에서는 그것이 핵심이 아니므로 생략합니다.\n",
    "\n",
    "이제 같은 dataloader를 그대로 활용해서 domain adaptation 실험을 이어가봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bO4c_QcGtm4z"
   },
   "source": [
    "# Domain Adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJwcwLQftm40"
   },
   "source": [
    "Domain adaptation의 핵심 구조는 fine-tuning과 매우 비슷하지만,\n",
    "두 도메인 간 분포 차이를 줄이기 위한 loss function을 추가해야 합니다.\n",
    "\n",
    "여기서는 MMD와 Coral loss를 사용해 두 도메인 간 분포 차이를 계산하는 loss function을 정의합니다. \n",
    "\n",
    "해당 loss를 이용할 수 있도록 새로운 모델 클래스를 정의하고 source의 feature와 label, 그리고 target feature를 모두 이용하도록 학습 스크립트를 수정해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jy_1xwdJtm40"
   },
   "source": [
    "### Loss function\n",
    "Domain Adaptation에서 가장 많이 사용되는 손실 함수는 MMD (Maximum Mean Discrepancy)입니다.\n",
    "\n",
    "비교를 위해 또 다른 대표적인 손실 함수인 CORAL (CORrelation ALignment)도 함께 살펴봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3-wKorUtm40"
   },
   "source": [
    "#### MMD loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MpQH6VFwtm41"
   },
   "outputs": [],
   "source": [
    "class MMD_loss(nn.Module):\n",
    "    def __init__(self, kernel_type='rbf', kernel_mul=2.0, kernel_num=5):\n",
    "        super(MMD_loss, self).__init__()\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.fix_sigma = None\n",
    "        self.kernel_type = kernel_type\n",
    "\n",
    "    def guassian_kernel(self, source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "        n_samples = int(source.size()[0]) + int(target.size()[0])\n",
    "        total = torch.cat([source, target], dim=0)\n",
    "        total0 = total.unsqueeze(0).expand(\n",
    "            int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        total1 = total.unsqueeze(1).expand(\n",
    "            int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        L2_distance = ((total0-total1)**2).sum(2)\n",
    "        if fix_sigma:\n",
    "            bandwidth = fix_sigma\n",
    "        else:\n",
    "            bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "        bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "        bandwidth_list = [bandwidth * (kernel_mul**i)\n",
    "                          for i in range(kernel_num)]\n",
    "        kernel_val = [torch.exp(-L2_distance / bandwidth_temp)\n",
    "                      for bandwidth_temp in bandwidth_list]\n",
    "        return sum(kernel_val)\n",
    "\n",
    "    def linear_mmd2(self, f_of_X, f_of_Y):\n",
    "        loss = 0.0\n",
    "        delta = f_of_X.float().mean(0) - f_of_Y.float().mean(0)\n",
    "        loss = delta.dot(delta.T)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        if self.kernel_type == 'linear':\n",
    "            return self.linear_mmd2(source, target)\n",
    "        elif self.kernel_type == 'rbf':\n",
    "            batch_size = int(source.size()[0])\n",
    "            kernels = self.guassian_kernel(\n",
    "                source, target, kernel_mul=self.kernel_mul, kernel_num=self.kernel_num, fix_sigma=self.fix_sigma)\n",
    "            XX = torch.mean(kernels[:batch_size, :batch_size])\n",
    "            YY = torch.mean(kernels[batch_size:, batch_size:])\n",
    "            XY = torch.mean(kernels[:batch_size, batch_size:])\n",
    "            YX = torch.mean(kernels[batch_size:, :batch_size])\n",
    "            loss = torch.mean(XX + YY - XY - YX)\n",
    "            return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcfUy_2Dtm41"
   },
   "source": [
    "#### CORAL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uZhKJq15tm41"
   },
   "outputs": [],
   "source": [
    "def CORAL(source, target):\n",
    "    d = source.size(1)\n",
    "    ns, nt = source.size(0), target.size(0)\n",
    "\n",
    "    # source covariance\n",
    "    tmp_s = torch.ones((1, ns)).cuda() @ source\n",
    "    cs = (source.t() @ source - (tmp_s.t() @ tmp_s) / ns) / (ns - 1)\n",
    "\n",
    "    # target covariance\n",
    "    tmp_t = torch.ones((1, nt)).cuda() @ target\n",
    "    ct = (target.t() @ target - (tmp_t.t() @ tmp_t) / nt) / (nt - 1)\n",
    "\n",
    "    # frobenius norm\n",
    "    loss = (cs - ct).pow(2).sum().sqrt()\n",
    "    loss = loss / (4 * d * d)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB2cDp8Gtm41"
   },
   "source": [
    "### Model\n",
    "여기서도 backbone으로는 ResNet-50을 사용합니다.\n",
    "다만 이번에는 ResNet-50의 마지막 classifier layer를 제거한 feature extractor로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UOLx_OSxtm41"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "class ResNet50Fc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50Fc, self).__init__()\n",
    "        model_resnet50 = models.resnet50(pretrained=True)\n",
    "        self.conv1 = model_resnet50.conv1\n",
    "        self.bn1 = model_resnet50.bn1\n",
    "        self.relu = model_resnet50.relu\n",
    "        self.maxpool = model_resnet50.maxpool\n",
    "        self.layer1 = model_resnet50.layer1\n",
    "        self.layer2 = model_resnet50.layer2\n",
    "        self.layer3 = model_resnet50.layer3\n",
    "        self.layer4 = model_resnet50.layer4\n",
    "        self.avgpool = model_resnet50.avgpool\n",
    "        self.__in_features = model_resnet50.fc.in_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "    def output_num(self):\n",
    "        return self.__in_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRgdNM3Wtm42"
   },
   "source": [
    "이제 Domain Adaptation을 위한 핵심 모델 클래스를 정의합니다.\n",
    "\n",
    "ResNet-50을 기반으로 하되, bottleneck layer와 새로운 fc layer를 추가합니다.\n",
    "\n",
    "중요한 점은 adapt_loss 함수로 우리가 정의한 MMD 또는 CORAL loss를 forward pass에서 함께 계산한다는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "oC5NKJpJtm42"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# MMD_loss와 CORAL 함수는 별도로 정의되어 있어야 합니다.\n",
    "def MMD_loss(x, y):\n",
    "    # 실제 구현에 맞게 작성\n",
    "    return torch.tensor(0.0, device=x.device)\n",
    "\n",
    "def CORAL(x, y):\n",
    "    # 실제 구현에 맞게 작성\n",
    "    return torch.tensor(0.0, device=x.device)\n",
    "\n",
    "class TransferNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_class, \n",
    "                 base_net='resnet50', \n",
    "                 transfer_loss='mmd', \n",
    "                 use_bottleneck=True, \n",
    "                 bottleneck_width=256, \n",
    "                 width=1024):\n",
    "        super(TransferNet, self).__init__()\n",
    "        \n",
    "        if base_net == 'resnet50':\n",
    "            # TODO: ResNet50 기반 feature extractor를 정의\n",
    "            # fc layer를 제거한 후, Flatten까지 적용하여 feature extractor로 사용\n",
    "            model_resnet50 = models.resnet50(pretrained=True)\n",
    "            modules = list(model_resnet50.children())[:-1]  # fc 레이어 제거\n",
    "            self.base_network = nn.Sequential(*modules, nn.Flatten())\n",
    "        else:\n",
    "            # Your own basenet\n",
    "            raise NotImplementedError(\"현재는 resnet50만 지원합니다.\")\n",
    "        \n",
    "        self.use_bottleneck = use_bottleneck\n",
    "        self.transfer_loss = transfer_loss\n",
    "        \n",
    "        # TODO: bottleneck layer를 정의 (2048 -> bottleneck_width)\n",
    "        bottleneck_list = [\n",
    "            nn.Linear(2048, bottleneck_width),\n",
    "            nn.BatchNorm1d(bottleneck_width),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "        self.bottleneck_layer = nn.Sequential(*bottleneck_list)\n",
    "        \n",
    "        # TODO: classifier layer를 정의 (bottleneck_width -> width -> num_class)\n",
    "        classifier_layer_list = [\n",
    "            nn.Linear(bottleneck_width, width),\n",
    "            nn.BatchNorm1d(width),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(width, num_class)\n",
    "        ]\n",
    "        self.classifier_layer = nn.Sequential(*classifier_layer_list)\n",
    "        \n",
    "        # Bottleneck layer 초기화: 첫 번째 Linear layer 초기화\n",
    "        self.bottleneck_layer[0].weight.data.normal_(0, 0.005)\n",
    "        self.bottleneck_layer[0].bias.data.fill_(0.1)\n",
    "        \n",
    "        # Classifier layer의 두 Linear 계층 초기화 (index 0와 index 4에 위치)\n",
    "        for idx in [0, 4]:\n",
    "            self.classifier_layer[idx].weight.data.normal_(0, 0.01)\n",
    "            self.classifier_layer[idx].bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        # 1. Feature extraction: ResNet50을 통해 2048차원 피처 추출\n",
    "        source_features = self.base_network(source)\n",
    "        target_features = self.base_network(target)\n",
    "        \n",
    "        # 2. Bottleneck layer를 적용하여 차원을 2048 -> 256으로 축소\n",
    "        if self.use_bottleneck:\n",
    "            source_bn = self.bottleneck_layer(source_features)\n",
    "            target_bn = self.bottleneck_layer(target_features)\n",
    "        else:\n",
    "            source_bn = source_features\n",
    "            target_bn = target_features\n",
    "        \n",
    "        # 3. 축소된 피처를 classifier_layer에 전달하여 분류 결과 산출\n",
    "        source_clf = self.classifier_layer(source_bn)\n",
    "        \n",
    "        # 4. 전이 손실(adapt_loss)는 bottleneck을 통과한 피처(256차원)를 이용해 계산\n",
    "        transfer_loss = self.adapt_loss(source_bn, target_bn, self.transfer_loss)\n",
    "        \n",
    "        return source_clf, transfer_loss\n",
    "\n",
    "    def predict(self, x):\n",
    "        features = self.base_network(x)\n",
    "        if self.use_bottleneck:\n",
    "            features = self.bottleneck_layer(features)\n",
    "        clf = self.classifier_layer(features)\n",
    "        return clf\n",
    "\n",
    "    def adapt_loss(self, X, Y, adapt_loss):\n",
    "        \"\"\"Compute adaptation loss, currently we support mmd and coral\n",
    "\n",
    "        Arguments:\n",
    "            X {tensor} -- source matrix\n",
    "            Y {tensor} -- target matrix\n",
    "            adapt_loss {string} -- loss type, 'mmd' or 'coral'. You can add your own loss\n",
    "\n",
    "        Returns:\n",
    "            [tensor] -- adaptation loss tensor\n",
    "        \"\"\"\n",
    "        if adapt_loss == 'mmd':\n",
    "            loss = MMD_loss(X, Y)\n",
    "        elif adapt_loss == 'coral':\n",
    "            loss = CORAL(X, Y)\n",
    "        else:\n",
    "            # Your own loss\n",
    "            loss = 0\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAdPs27btm42"
   },
   "source": [
    "### Train\n",
    "이제 Domain Adaptation 모델을 학습시켜 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OK6P8uMDtm42"
   },
   "outputs": [],
   "source": [
    "transfer_loss = 'mmd'\n",
    "learning_rate = 0.0001\n",
    "transfer_model = TransferNet(n_class, transfer_loss=transfer_loss, base_net='resnet50').cuda()\n",
    "optimizer = torch.optim.SGD([\n",
    "    {'params': transfer_model.base_network.parameters()},\n",
    "    {'params': transfer_model.bottleneck_layer.parameters(), 'lr': 10 * learning_rate},\n",
    "    {'params': transfer_model.classifier_layer.parameters(), 'lr': 10 * learning_rate},\n",
    "], lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "lamb = 10 # weight for transfer loss, it is a hyperparameter that needs to be tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WpUfcHItm42"
   },
   "source": [
    "학습 함수에서는 source 데이터와 label, target 데이터를 모두 사용해야 하므로, source와 target의 dataloader를 zip으로 묶어서 동시에 iterate합니다.\n",
    "\n",
    "보통 두 도메인의 샘플 수는 다르기 때문에, 여러 epoch에 걸쳐 무작위로 잘 섞이면 전체 데이터를 충분히 학습할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "AGlVNI2ktm42"
   },
   "outputs": [],
   "source": [
    "def train(dataloaders, model, optimizer):\n",
    "    source_loader, target_train_loader, target_test_loader = dataloaders['src'], dataloaders['val'], dataloaders['tar']\n",
    "    len_source_loader = len(source_loader)\n",
    "    len_target_loader = len(target_train_loader)\n",
    "    best_acc = 0\n",
    "    stop = 0\n",
    "    n_batch = min(len_source_loader, len_target_loader)\n",
    "    for e in range(n_epoch):\n",
    "        stop += 1\n",
    "        train_loss_clf, train_loss_transfer, train_loss_total = 0, 0, 0\n",
    "        model.train()\n",
    "        for (src, tar) in zip(source_loader, target_train_loader):\n",
    "            data_source, label_source = src\n",
    "            data_target, _ = tar\n",
    "            data_source, label_source = data_source.cuda(), label_source.cuda()\n",
    "            data_target = data_target.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            label_source_pred, transfer_loss = model(data_source, data_target)\n",
    "            clf_loss = criterion(label_source_pred, label_source)\n",
    "            loss = clf_loss + lamb * transfer_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_clf = clf_loss.detach().item() + train_loss_clf\n",
    "            train_loss_transfer = transfer_loss.detach().item() + train_loss_transfer\n",
    "            train_loss_total = loss.detach().item() + train_loss_total\n",
    "        acc = test(model, target_test_loader)\n",
    "        print(f'Epoch: [{e:2d}/{n_epoch}], cls_loss: {train_loss_clf/n_batch:.4f}, transfer_loss: {train_loss_transfer/n_batch:.4f}, total_Loss: {train_loss_total/n_batch:.4f}, acc: {acc:.4f}')\n",
    "        if best_acc < acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), 'trans_model.pkl')\n",
    "            stop = 0\n",
    "        if stop >= early_stop:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nqSCG6-Xtm43",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0/100], cls_loss: 3.1111, transfer_loss: 0.0000, total_Loss: 3.1111, acc: 0.4126\n",
      "Epoch: [ 1/100], cls_loss: 2.2522, transfer_loss: 0.0000, total_Loss: 2.2522, acc: 0.6113\n",
      "Epoch: [ 2/100], cls_loss: 1.7121, transfer_loss: 0.0000, total_Loss: 1.7121, acc: 0.6755\n",
      "Epoch: [ 3/100], cls_loss: 1.4311, transfer_loss: 0.0000, total_Loss: 1.4311, acc: 0.7082\n",
      "Epoch: [ 4/100], cls_loss: 1.1742, transfer_loss: 0.0000, total_Loss: 1.1742, acc: 0.7220\n",
      "Epoch: [ 5/100], cls_loss: 1.0703, transfer_loss: 0.0000, total_Loss: 1.0703, acc: 0.7283\n",
      "Epoch: [ 6/100], cls_loss: 1.1098, transfer_loss: 0.0000, total_Loss: 1.1098, acc: 0.7107\n",
      "Epoch: [ 7/100], cls_loss: 0.9543, transfer_loss: 0.0000, total_Loss: 0.9543, acc: 0.7157\n",
      "Epoch: [ 8/100], cls_loss: 0.8642, transfer_loss: 0.0000, total_Loss: 0.8642, acc: 0.7006\n",
      "Epoch: [ 9/100], cls_loss: 0.7424, transfer_loss: 0.0000, total_Loss: 0.7424, acc: 0.7396\n",
      "Epoch: [10/100], cls_loss: 0.7894, transfer_loss: 0.0000, total_Loss: 0.7894, acc: 0.7182\n",
      "Epoch: [11/100], cls_loss: 0.7337, transfer_loss: 0.0000, total_Loss: 0.7337, acc: 0.7283\n",
      "Epoch: [12/100], cls_loss: 0.7271, transfer_loss: 0.0000, total_Loss: 0.7271, acc: 0.7220\n",
      "Epoch: [13/100], cls_loss: 0.7417, transfer_loss: 0.0000, total_Loss: 0.7417, acc: 0.6830\n",
      "Epoch: [14/100], cls_loss: 0.6629, transfer_loss: 0.0000, total_Loss: 0.6629, acc: 0.7082\n",
      "Epoch: [15/100], cls_loss: 0.6205, transfer_loss: 0.0000, total_Loss: 0.6205, acc: 0.7119\n",
      "Epoch: [16/100], cls_loss: 0.6075, transfer_loss: 0.0000, total_Loss: 0.6075, acc: 0.7396\n",
      "Epoch: [17/100], cls_loss: 0.6926, transfer_loss: 0.0000, total_Loss: 0.6926, acc: 0.7270\n",
      "Epoch: [18/100], cls_loss: 0.5686, transfer_loss: 0.0000, total_Loss: 0.5686, acc: 0.7119\n",
      "Epoch: [19/100], cls_loss: 0.6512, transfer_loss: 0.0000, total_Loss: 0.6512, acc: 0.7283\n",
      "Epoch: [20/100], cls_loss: 0.5516, transfer_loss: 0.0000, total_Loss: 0.5516, acc: 0.7270\n",
      "Epoch: [21/100], cls_loss: 0.5297, transfer_loss: 0.0000, total_Loss: 0.5297, acc: 0.7283\n",
      "Epoch: [22/100], cls_loss: 0.5696, transfer_loss: 0.0000, total_Loss: 0.5696, acc: 0.7421\n",
      "Epoch: [23/100], cls_loss: 0.5662, transfer_loss: 0.0000, total_Loss: 0.5662, acc: 0.7358\n",
      "Epoch: [24/100], cls_loss: 0.4909, transfer_loss: 0.0000, total_Loss: 0.4909, acc: 0.7233\n",
      "Epoch: [25/100], cls_loss: 0.5243, transfer_loss: 0.0000, total_Loss: 0.5243, acc: 0.7220\n",
      "Epoch: [26/100], cls_loss: 0.5392, transfer_loss: 0.0000, total_Loss: 0.5392, acc: 0.7258\n",
      "Epoch: [27/100], cls_loss: 0.4974, transfer_loss: 0.0000, total_Loss: 0.4974, acc: 0.7233\n",
      "Epoch: [28/100], cls_loss: 0.5135, transfer_loss: 0.0000, total_Loss: 0.5135, acc: 0.7094\n",
      "Epoch: [29/100], cls_loss: 0.5125, transfer_loss: 0.0000, total_Loss: 0.5125, acc: 0.7132\n",
      "Epoch: [30/100], cls_loss: 0.4342, transfer_loss: 0.0000, total_Loss: 0.4342, acc: 0.7208\n",
      "Epoch: [31/100], cls_loss: 0.4443, transfer_loss: 0.0000, total_Loss: 0.4443, acc: 0.7308\n",
      "Epoch: [32/100], cls_loss: 0.4875, transfer_loss: 0.0000, total_Loss: 0.4875, acc: 0.7258\n",
      "Epoch: [33/100], cls_loss: 0.4100, transfer_loss: 0.0000, total_Loss: 0.4100, acc: 0.7270\n",
      "Epoch: [34/100], cls_loss: 0.4612, transfer_loss: 0.0000, total_Loss: 0.4612, acc: 0.7182\n",
      "Epoch: [35/100], cls_loss: 0.4786, transfer_loss: 0.0000, total_Loss: 0.4786, acc: 0.7069\n",
      "Epoch: [36/100], cls_loss: 0.4676, transfer_loss: 0.0000, total_Loss: 0.4676, acc: 0.7208\n",
      "Epoch: [37/100], cls_loss: 0.4252, transfer_loss: 0.0000, total_Loss: 0.4252, acc: 0.7157\n",
      "Epoch: [38/100], cls_loss: 0.4452, transfer_loss: 0.0000, total_Loss: 0.4452, acc: 0.7107\n",
      "Epoch: [39/100], cls_loss: 0.4836, transfer_loss: 0.0000, total_Loss: 0.4836, acc: 0.7195\n",
      "Epoch: [40/100], cls_loss: 0.3888, transfer_loss: 0.0000, total_Loss: 0.3888, acc: 0.7333\n",
      "Epoch: [41/100], cls_loss: 0.3568, transfer_loss: 0.0000, total_Loss: 0.3568, acc: 0.7270\n",
      "Epoch: [42/100], cls_loss: 0.3752, transfer_loss: 0.0000, total_Loss: 0.3752, acc: 0.7396\n"
     ]
    }
   ],
   "source": [
    "# TODO: Domain Adaptation 모델을 학습시키는 함수를 호출하여 학습 진행\n",
    "train(dataloaders, transfer_model, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "yWvYODRDtm43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7421383647798742\n"
     ]
    }
   ],
   "source": [
    "transfer_model.load_state_dict(torch.load('trans_model.pkl'))\n",
    "acc_test = test(transfer_model, dataloaders['tar'])\n",
    "print(f'Test accuracy: {acc_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "deep_transfer_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
